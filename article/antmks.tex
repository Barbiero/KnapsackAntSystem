\section{Aplicando o Problema da Mochila ao Ant System}
No Problema da Mochila, soluções válidas podem ser interpretados como estados em que a mochila se encontra. Assim, uma mochila começa em um estado inicial onde suas capacidades $C_k$ estão em seu valor máximo, e nenhum item está adicionado à mochila.

A transição de estados da mochila é dada pela adição de um novo item na mesma; Ao adicionar um novo item, as restrições $C_k$ são reduzidas de acordo com os atributos do item $i$, e o valor da mochila, e portanto qualidade da solução, cresce de acordo com $v_i$(o valor de $i$). Se um item possui uma restrição $w_{ik}>C_k$, então a mochila não pode adicionar este item nela - o que significa que o estado em que a mochila se encontra não é ligado à aresta a qual este item é representado.

Levando então a consideração de que o estado da mochila é um nó, e o item é uma aresta, basta determinar uma fórmula para a atratividade $\mu$ dos itens.

Como o intuito deste trabalho é mostrar a paralelização do \textit{ACO}, não foi feito uma análise extensa sobre qual $\mu$ provém os melhores resultados em menos iterações. Usaremos então uma fórmula baseada no trabalho de Schiff, K\cite{aco:schiff}, a qual é simples de calcular:
$$
	\mu_j = \dfrac{v_j}{
		\prod r_{ij}}
$$
Onde $r_{ij}$ são todas as restrições de um item $j$ e $v_j$ é o valor do item $j$.

Dado então um número de iterações $iter$, um número de formigas $ants$ e um número de itens $n$ onde cada item possui $m$ restrições e um valor $v_j$, um valor inicial de feromônio $\varphi$ e um valor máximo de feromônio $\varphi_{\max}$, assim como capacidade máxima da mochila $C_k$, $0<k<m$, constrói-se o algoritmo final no Algoritmo \ref{acoseq}.

\begin{algorithm}[ht]
	\KwIn{\\
		$iter$: Número de iterações do sistema\\
		$ants$: Número de formigas do sistema\\
		$n$: Número de itens\\
		$m$: Número de restrições\\
		$C_k, 0<k<m$: Capacidade da mochila\\
		$v_j, 0<j<n$: Valor do item $j$\\
		$r_{ij}, 0<j<n, 0<i<m$: Restrição $i$ do item $j$\\
		$\mu_j = \dfrac{v_j}{
			\prod r_{ij}}$: Atratividade do item $j$\\
		$\varphi, \varphi_{\max}$: Valor inicial e máximo de feromônio\\
		$\rho$: Coeficiente de evaporação do feromônio\\
		$\alpha$: Peso que o feromônio tem sobre a seleção dos itens\\
		$\beta$: Peso que a atratividade tem sobre a seleção dos itens\\
	}
	
	\KwOut{$S$: estado da mochila na solução final}
	$best = \emptyset$\;
	$\forall_{0<j<n} \tau_j \gets \varphi$\;
	\While{$iter{-}{-} > 0$ }{
		$best_x\gets\emptyset \qquad \forall_{0<x<ants}$\;
		\BlankLine
		\textit{//Buscar uma solução}\;
		\For{$x\gets 0 $\textbf{ to }$ ants$}{
			$solucao\gets constroi\_solucao()$\;
			\If{($solucao > best_x$)}{$best_x\gets solucao$}
			\If{($solucao > best$)}{$best\gets solucao$}	
		}
		\BlankLine
		\textit{//Atualizar feromonio}\;
		\For{$j\gets0$ \textbf{to} $n$}{
			$\tau_j \gets \tau_j * \rho$\;
		}
		\For{$x\gets0$ \textbf{to} $ ants$}{
			\ForEach{$i$: Item $\in best_x$}{
				$\tau_i \gets \Delta\tau(best_x)$\;	
			}
		}
		
		Atualizar $\tau_j^\alpha \mu_j^\beta$ para cada item\;
	}
	return $best$\;
	\caption{Algoritmo sequencial para o ACO}
	\label{acoseq}
\end{algorithm} 

\section{Paralelização do \textit{ACO} no modelo de memória distribuída}
Uma das vantagens de um modelo de memória distribuída é que precisa-se se preocupar apenas com a informação que \textit{deve} ser distribuída entre diferentes nós do processo. No caso do \textit{ACO}, se assumirmos que todos os nós em execução possuem acesso a todos os itens do universo, e que todos os nós são capazes de construir uma solução dada um feromônio, nota-se que a única váriavel é de fato compartilhada e modificada entre as formigas é o feromônio em si: $\tau_j$ depende de cada solução encontrada por cada formiga, porém todas as outras variáveis, inclusive o composto entre Feromônio e Desejabilidade $\tau_j^\alpha \mu_j^\beta$, podem ser calculadas antes ou depois de se determinar o valor do feromônio em uma dada iteração.

\subsection{Lista de atualização de feromônio}
Quando um conjunto de formigas termina sua iteração - isto é, encontram uma solução válida e estão prontas para atualizar o feromônio - é possível criar uma lista $\Delta\tau_j \forall{j}$ tal o índice $j$ indica qual será a diferença linear do feromônio após a evaporação com o feromônio após o término da atualização. Esta lista é relativamente pequena - cada elemento pode ser dado por um par \texttt{\{int, double\}} que tem um tamanho de 12 bytes na maioria dos sistema; e uma lista de atualização iria conter apenas os itens que irão, de fato, receber um aumento de feromônio além da evaporação; Isto é especialmente útil pois no problema da mochila, apenas um subconjunto pequeno de itens é incluso na mochila em um grande universo.

\subsection{Envio da Mensagem}
Pode-se então utilizar a função \texttt{Broadcast} para enviar a lista de feromônios para todos os nós do sistema, onde cada nó possui um subconjunto de formigas(em geral, ${num\_ants}\div{num\_nos}$). Assim, cada nó irá receber as listas de todos os outros nós, onde então todos os nós irão somar as partes das listas para atualizar suas listas locais de feromônio - minimizando, assim, o tamanho e número de mensagens a serem enviadas no sistema.

Finalmente, ao término do programa(neste caso, do número de iterações), os nós podem então enviar seus melhores resultados ao nó de rank $0$ para que este possa finalizar a execução do programa com o resultado geral final.





A forma mais intuitiva de se paralelizar o \textit{ACO} é em paralelizar as formigas, ou seja, enviar as formigas em \textit{threads} separadas para que trabalhem de forma concorrente. Durante a construção de solução, não existem problemas de concorrência: variáveis globais como $\tau_i$ não são modificadas.

\subsection{Regiões críticas}
Nota-se também que o algoritmo sequencial(\ref{acoseq}) possui 4 estágios bem definidos: Construção de soluções, Evaporação de feromônio, Atualização de feromônio e Atualização da probabilidade de escolha $\tau_j^\alpha \mu_j^\beta$. Existe também uma ordem específica em que cada um destes estágios precisam ocorrer: Não se pode evaporar o feromônio antes de terminar de construir as soluções, pois estas são dependentes do feromônio. Também não se pode atualizar o feromônio antes da evaporação pois isto mudará o valor final da operação; e com certeza não se pode atualizar o feromônio \textit{durante} a evaporação. Também não se pode atualizar $\tau_j^\alpha \mu_j^\beta$ antes que o feromônio esteja completamente atualizado, e não se pode construir uma nova solução antes que $\tau_j^\alpha \mu_j^\beta$ esteja atualizado em cada item.

Isto indica que o algoritmo irá se beneficiar do uso de \textbf{barreiras}, impedindo que cada thread continue sua execução antes que todas as threads terminem o estágio específico em que se encontram. Além disso, um lock será necessário para impedir que $\tau_i$ seja modificado por várias threads ao mesmo tempo. O algoritmo \ref{acopar} mostra como ele irá funcionar para uma Thread. Para o programa final, basta verificar qual thread produziu a melhor solução.

\begin{algorithm}[ht]
		\KwIn{\\
			$N$: O numero total de nós\\
			$rank$: O identificador do nó no comunicador global, $1\leq rank \leq N$\\
			$iter$: Número de iterações do sistema\\
			$ants$: Número de formigas por nó, onde $ants * N$ dá o número total de formigas\\
			$n$: Número de itens\\
			$m$: Número de restrições\\
			$C_k, 0<k<m$: Capacidade da mochila\\
			$v_j, 0<j<n$: Valor do item $j$\\
			$r_{ij}, 0<j<n, 0<i<m$: Restrição $i$ do item $j$\\
			$\mu_j = \dfrac{v_j}{
				\prod r_{ij}}$: Atratividade do item $j$\\
			$\varphi, \varphi_{\max}$: Valor inicial e máximo de feromônio\\
			$\rho$: Coeficiente de evaporação do feromônio\\
			$\alpha$: Peso que o feromônio tem sobre a seleção dos itens\\
			$\beta$: Peso que a atratividade tem sobre a seleção dos itens\\
		}
		
		\KwOut{$S$: estado da mochila na solução final}
		
		
		$\forall_{0<j<n} \tau_j \gets \varphi$\;
		\While{$iter{-}{-} > 0$ }{
			$best_x\gets\emptyset \qquad \forall_{0<x<ants}$\;
			\BlankLine
			\For{$x\gets 1 $\textbf{ to }$ ants$}{
				$solucao\gets constroi\_solucao()$\;
				\If{($solucao > best_x$)}{$best_x\gets solucao$}
			}
			$\Delta\tau_j \gets \Delta\tau(best_x) \qquad \forall_j \in best$ \;
			$\Delta\tau' \gets \Delta\tau$
			\BlankLine
			\For{$i \gets 1 $ \textbf{to} $ N$}{
				$\Delta\phi <- \emptyset$\;
				\If{$rank = i$}{
					$\Delta\phi <- \Delta\tau'$\;	
				}
				\texttt{Broadcast}($\Delta\phi, i$, \texttt{MPI\_COMM\_WORLD})\;
				$\Delta\tau \gets \Delta\tau + \Delta\phi$\;
			}
			
			\For{$j \gets 1$ \textbf{to} $ n$}{
				$\tau_j \gets \tau_j * \rho + \Delta\tau_j$\;
				Atualizar $\tau_j^\alpha \mu_j^\beta$\;
			}
		}
		return $best$\;
		\caption{Algoritmo de uma thread para o ACO}
		\label{acopar}
\end{algorithm}

\subsection{Análise de desempenho}
O programa foi implementado na linguagem \texttt{C}, padrão \texttt{C11}, compilado com gcc versão 5.3.0 sob otimização \texttt{-O2}, e executado em um e duas máquinas com processador \textbf{i7 @ 3.5GHz}. A execução ocorreu no sistema operacional Ubuntu 14.04.

Para a coleta de dados, o programa foi executado em 1, 2, 3, 4, 8 e 16 nós, sendo testado o desempenho com uma distribuição de instâncias por máquina e por \textit{slot}, limitando cada máquina a 4 slots. Um gráfico do \textit{speedup} de cada instância pode ser verificado na figura \ref{Speedup}.

\input{outplot}

Imediatamente nota-se que existe uma \textit{Superlinearidade} no \textit{speedup} dos programas em uma instância em particular: Quando o número de nós é igual ao número total de núcleos físicos de processamento. A hipótese deste fenômeno ter ocorrido se dá ao modo em que o processador i7 se comporta quando sobre uma grande carga de processos ou com o modo em que o sistema operacional escalona os processos quando nesta instância em específica. Testes de outras instâncias não registrados mostram um padrão neste fenômeno em que o speedup superlinear é diretamente relacionado a este número de processos(4 por máquina).

Nota-se também o fenômeno mais esperado de que, ao passar do número de processadores físicos, ocorre uma queda na eficiência de processamento pois o sistema estará passando uma grande quantidade de tempo escalonando os processos - ocorrendo um slowdown perceptível quando o número de processos começa a ficar muito maior do que o número de núcleos de processamento.

Atribui-se o alto desempenho ao fato de que as mensagens passadas são pequenas e rapidamente processadas entre nós; Além disso, os computadores se encontravam fisicamente próximos e é esperado que uma rede mais congestionada ou esparsa, ou mesmo um aumento no número de máquinas, causaria uma perda de eficácia em relação às instâncias testadas. Mesmo assim, o ganho de tempo no processamento distribuído para uma instância suficientemente grande sobrepõe qualquer perda de eficácia gerada por uma rede esparsa.


A implementação do projeto está disponível em \url{https://github.com/Barbiero/KnapsackAntSystem/tree/mpibranch}.
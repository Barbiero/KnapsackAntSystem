\section{Paralelização do Algoritmo em Memória Distribuída}
Programas sequenciais podem ser programados, com a ajuda de uma biblioteca específica, de tal forma que eles possam ser executados em múltiplas instâncias através de diversas máquinas interligadas em rede(local ou internet). A \textbf{Message Passing Interface}, ou MPI, é o modelo de bibliotecas para um sistema de passagem de mensagens; Neste trabalho em específico foi-se utilizada a biblioteca \texttt{mpich}, que implementa este modelo.

\subsection{Conceitos básicos do MPI}
Alguns conceitos precisam ser compreendidos para entender como o MPI funciona, e como o programa pode tirar vantagem destes conceitos para resolver problemas sobre múltiplas máquinas ou processadores. Primeiramente, deve-se entender como \textbf{nó} uma instância de um programa que pode se comunicar com outros nós de mesmo tipo; Esta comunicação não é detalhada pois pode ocorrer internamente(na mesma máquina) ou externamente(entre diferentes máquinas), e ela pode ocorrer de acordo com o protocolo de comunicação definido pelo MPI - para o programa e o algoritmo em questão, esta comunicação é abstraída e tratada pela biblioteca.

\subsubsection{Comunicadores}
No MPI, um \textbf{comunicador} é um conjunto de um ou mais nós que fazem parte, de forma lógica, de um mesmo grupo de comunicação. Comunicadores são utilizados para determinar a topologia dos nós em execução assim como organizar as passagens de mensagem(principalmente as do tipo \textit{broadcast}). Por padrão, um comunicador global chamado \texttt{MPI\_COMM\_WORLD} é definido na inicialização dos nós, e este comunicador irá englobar todos os nós do sistema.

Neste projeto, foi-se utilizada uma topologia do tipo \textbf{estrela}; Isto significa que todos os nós irão passar mensagens entre todos os outros nós, significando que o comunicador \texttt{MPI\_COMM\_WORLD} será o único criado.

\subsubsection{Rank \& Size}
A identificação de um dado nó é dada por seu \textbf{rank} dentro de um comunicador; O comunicador, por sua vez, possui um número de nós variável que é dado por \textbf{size}, e cada nó pertencente a um comunicador obedece à lei de $0\leq rank_{no}<Size_{comm}$.

Neste projeto, um rank em particular, o rank $0$, é especificado como o nó que irá produzir a saída de dados; Além de imprimir na tela(ou arquivo de saída) o resultado do programa, o nó com rank 0 não difere dos outros nós em execução.

\subsubsection{Send, Receive, Broadcast}
Em um sistema baseado em passagem de mensagens, alguns comandos devem ser definidos para que estas mensagens sejam, de fato, passadas. A função \texttt{Send} envia uma quantidade de bytes para um certo nó alvo com uma \textit{tag}, sendo que estes bytes contém alguma informação útil(a mensagem) para o programa alvo. Para cada chamada de \texttt{Send} de uma fonte a um destino, deve haver uma chamada, no destino, da função \texttt{Receive} que indica a fonte da mensagem assim como o tamanho da mensagem e o tipo da mesma. Estruturas complexas(\texttt{struct}, em C) devem ser registradas em cada um dos nós que executam estas funções para que estes mantenham uma sincronia entre suas comunicações.

Já o comando \texttt{Broadcast} recebe como parâmetro uma variável, o tamanho dela, um nó fonte e um comunicador. Esta função irá então recuperar a informação contida nesta variável no nó fonte e enviá-la para todos os nós que fazem parte deste comunicador, que irão receber a informação e registrá-la na variável que eles possuem(lembrando que cada nó possui seu próprio conjunto de memória e de variáveis). Assim, é possível enviar uma informação a diversos nós de forma eficiente(sem a necessidade de múltiplas chamadas de \texttt{Send} e \texttt{Receive}).

\subsection{Distribuição de Instâncias e Execução}
A execução do algoritmo será feita em auxílio do programa \texttt{mpirun}, que recebe como parâmetros o número de nós a ser executado, os \textit{hosts}, ou máquinas, que irão executar o programa, além do próprio programa com seus próprios argumentos.

As instâncias de execução podem ser distribuídas de duas formas: por máquina ou por \textit{slot}. Na distribuição por máquina, cada máquina alvo receberá uma quantidade balanceada de instâncias, independente do hardware que a máquina executa; Já na distribuição por slot, pode-se determinar que uma máquina receba uma certa quantidade de instâncias antes de começar a criar novas instâncias na próxima máquina. Esta segunda forma de distribuição pode ser vantajosa, pois a comunicação entre nós em uma mesma máquina é mais rápida do que a comunicação entre nós de máquinas distintas(afinal, a comunicação é local), porém deve-se configurar manualmente exatamente quantos \textit{slots} uma máquina deve possuir antes de ser considerada "cheia".


\subsection{Leituras Adicionais}
O tópico de paralelização é muito mais extenso do que o escopo deste trabalho. Recomenda-se a leitura de outras fontes como \url{https://computing.llnl.gov/tutorials/parallel\_comp/#ModelsMessage/}\cite{parallelcomp:website}.
